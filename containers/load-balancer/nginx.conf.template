worker_processes auto;
error_log /dev/stderr crit;
pid /var/run/nginx.pid;

events {
    worker_connections 4000;
    use epoll;
    multi_accept on;
}

http {
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" $request_time '
                    '$upstream_addr $upstream_response_time $request_id';

    access_log /dev/stdout main;

    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 45;
    # number of requests client can make over keep-alive -- for testing environment
    keepalive_requests 100000;
    types_hash_max_size 2048;

    # cache informations about FDs, frequently accessed files
    # can boost performance, but you need to test those values
    open_file_cache max=200000 inactive=20s;
    open_file_cache_valid 30s;
    open_file_cache_min_uses 2;
    open_file_cache_errors on;

    # reduce the data that needs to be sent over network -- for testing environment
    gzip on;
    # gzip_static on;
    gzip_min_length 10240;
    gzip_comp_level 6;
    gzip_vary on;
    gzip_disable msie6;
    gzip_proxied expired no-cache no-store private auth;
    gzip_types
        # text/html is always compressed by HttpGzipModule
        text/css
        text/javascript
        text/xml
        text/plain
        text/x-component
        application/javascript
        application/x-javascript
        application/json
        application/xml
        application/rss+xml
        application/atom+xml
        font/truetype
        font/opentype
        application/vnd.ms-fontobject
        image/svg+xml;

    # allow the server to close connection on non responding client, this will free up memory
    reset_timedout_connection on;

    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=cache_image_webp:50m max_size=5g use_temp_path=off;

    upstream backend_servers {
        random two least_conn;
        ${UPSTREAM_CONFIG}
    }

    server {
        listen 7000;
        server_name _;

        add_header X-Lb-Request-ID $request_id;

        location /api/auth {
            proxy_pass ${AUTH_SERVER};
        }

        location /api/images {
            proxy_pass http://backend_servers;

            # Enable caching
            proxy_cache cache_image_webp;
            proxy_cache_valid 200 1y;
            proxy_cache_use_stale error timeout updating http_500 http_502 http_503 http_504;
            proxy_cache_lock on;

            # Set cache key to include query string
            proxy_cache_key $request_uri$is_args$args;

            # Add cache status header
            add_header X-Lb-Cache-Status $upstream_cache_status always;

            # Increase client body size if you're allowing image uploads
            client_max_body_size 10M;

            # Optimize sending of files
            sendfile on;
            tcp_nopush on;
            aio on;
        }

        location / {
            proxy_pass http://backend_servers;
            proxy_cache cache_image_webp;
            proxy_cache_use_stale error timeout updating http_500 http_502 http_503 http_504;
            add_header X-Lb-Cache-Status $upstream_cache_status always;
        }

        location /lb-stats {
            stub_status;
        }
    }

    ${SERVER_CONFIGS}
}
